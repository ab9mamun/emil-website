---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Reinforcement Learning: Basics"
event: EMIL Spring'25 Seminars
event_url:
location: Online (Zoom)
address:
  street:
  city:
  region:
  postcode:
  country:
summary: "Reinforcement Learning (RL) is a machine learning technique focused on optimizing decision-making through interaction with an environment, where an agent takes actions to maximize long-term rewards. RL involves a cycle of observation, action, reward, and state transition, requiring a balance between exploration and exploitation. The Markov Decision Process (MDP) provides a mathematical framework for RL, while Q-learning helps develop optimal policies using action-value updates. RL has applications in gaming, robotics, autonomous vehicles, healthcare, and finance, but challenges such as high data requirements, computational costs, safety concerns, and delayed rewards persist."
abstract: "Reinforcement Learning (RL) is a subset of machine learning focused on optimizing decision-making through trial and error. This presentation introduces the fundamental concepts of RL, including key components such as the agent, which learns and makes decisions, and the environment, with which the agent interacts. The agent takes actions that influence the environment, receives rewards as feedback, and aims to develop an optimal policy that maximizes cumulative rewards over time. RL operates on the principle of sequential decision-making, distinguishing it from other learning paradigms. The process follows a loop where the agent observes the environment, selects an action, receives a reward, and transitions to a new state, repeating this cycle to improve decision-making. A critical challenge in RL is balancing exploration and exploitation—exploration helps discover new strategies, while exploitation capitalizes on known rewards. The Markov Decision Process (MDP) provides a mathematical framework for RL, helping define states, actions, rewards, and policies to guide learning. One of the most well-known RL algorithms, Q-learning, allows an agent to learn an optimal policy using an action-value function (Q-function) that updates iteratively based on rewards and future predictions. RL has wide-ranging applications, including gaming (DOTA 2 bots), robotics (Boston Dynamics’ Spot), autonomous vehicles (Waymo), healthcare (insulin dosage optimization), and finance (trading algorithms). However, several challenges remain, such as the need for large datasets, computational costs, balancing exploration vs. exploitation, delayed rewards, and ensuring safety and stability in real-world applications. RL continues to be a powerful tool for complex decision-making but requires careful tuning and computational resources to achieve practical success."

# Talk start and end times.
# End time can optionally be hidden by prefixing the line with `#`.
date: 2025-02-26T12:00:00-07:00
date_end: 2025-02-26T12:30:00-07:00
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: 2025-03-06T11:00:00-07:00

authors: [Eric Kim]
tags: []

# Is this a featured talk? (true/false)
featured: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: Smart
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

# Optional filename of your slides within your talk's folder or a URL.
url_slides: slides.pptx
url_code:
url_pdf: 
url_video:

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: "slides"

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

