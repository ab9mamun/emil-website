---
title: "Multi-Time Attention Networks for Irregularly Sampled Time Series"
abstract: "Irregular sampling occurs in many time series modeling applications where it presents a significant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous time values and use an attention mechanism to produce a fixed-length representation of a time series containing a variable number of observations. We investigate the performance of this framework on interpolation and classification tasks using multiple datasets. Our results show that the proposed approach performs as well or better than a range of baseline and recently proposed models while offering significantly faster training times than current state-of-the-art methods."

summary: "This paper proposes a new deep learning framework for irregularly sampled time-series data that is called Multi-Time Attention Networks."
location: Online (Zoom)
date: 2023-01-18T12:00:00.000Z
date_end: 2023-01-18T12:30:00.000Z
all_day: false
links:
  - url: https://openreview.net/pdf?id=4c0J6lwQ4_
    name: "PDF"
  - url: slides.pdf
    name: "slides"
event: EMIL Spring'23 Seminars
event_url: " "
publishDate: 2023-01-18T20:56:00.000Z
draft: false
featured: false
authors:
  - chia-cheng-kuo
image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
---
