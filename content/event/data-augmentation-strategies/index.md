---
title: "Data Augmentation Strategies"
abstract: "Adversarial examples causing evasive predictions are widely used to evaluate and improve the robustness of machine learning models. However, current studies focus on supervised learning tasks, relying on the ground-truth data label, a targeted objective, or supervision from a trained classifier. In this paper, we propose a framework of generating adversarial examples for unsupervised models and demonstrate novel applications to data augmentation. Our framework exploits a mutual information neural estimator as an information-theoretic similarity measure to generate adversarial examples without supervision. We propose a new MinMax algorithm with provable convergence guarantees for efficient generation of unsupervised adversarial examples. Our framework can also be extended to supervised adversarial examples. When using unsupervised adversarial examples as a simple plug-in data augmentation tool for model retraining, significant improvements are consistently observed across different unsupervised tasks and datasets, including data reconstruction, representation learning, and contrastive learning. Our results show novel methods and considerable advantages in studying and improving unsupervised machine learning via adversarial examples."
summary: "In this talk, we present and discuss different strategies for data augmentation."
location: Online (Zoom)
date: 2022-09-14T12:00:00.000Z
date_end: 2022-09-14T12:30:00.000Z
all_day: false
links:
  - url: https://arxiv.org/abs/2103.01895
    name: "Paper"
  - url: slides.pdf
    name: "slides"
event: EMIL Fall'22 Seminars
event_url: " "
publishDate: 2022-09-14T20:56:00.000Z
draft: false
featured: false
authors:
  - chia-cheng-kuo
image:
  filename: featured.png
  focal_point: Smart
  preview_only: false
---
